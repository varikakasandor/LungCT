{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "from lime import lime_image\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TITAN RTX'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels=[\"Pulmonary tumour\",\"Pulmonary metastasis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/idms/PROJECTS/Lung/Verdicts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8835afa03c51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mverdict_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/idms/PROJECTS/Lung/Verdicts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstatistics_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/idms/PROJECTS/Lung/Statistics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverdict_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstatistics_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CT4/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CT4/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CT4/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CT4/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/CT4/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/idms/PROJECTS/Lung/Verdicts.csv'"
     ]
    }
   ],
   "source": [
    "verdict_df=pd.read_csv('/mnt/idms/PROJECTS/Lung/Verdicts.csv')\n",
    "statistics_df=pd.read_csv('/mnt/idms/PROJECTS/Lung/Statistics.csv')\n",
    "verdict_df.fillna(0,inplace=True)\n",
    "statistics_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases=len(verdict_df)\n",
    "pos_cases=int(statistics_df.iloc[-1][pos_labels].sum())\n",
    "neg_cases=total_cases-pos_cases\n",
    "used_cases=50\n",
    "prob_keep_pos=used_cases/(2*pos_cases)\n",
    "prob_keep_neg=used_cases/(2*neg_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "cts=[]\n",
    "labels=[]\n",
    "for patient_path in glob.iglob(f'/mnt/idms/PROJECTS/Lung/Tudo-Ulyssys-Unzipped/*'):\n",
    "    diseases=verdict_df.loc[verdict_df['PatientID'] == patient_path].iloc[0]\n",
    "    pos_diseases=np.array(diseases[pos_labels])\n",
    "    pos_or_neg=np.any(pos_diseases==1.0)\n",
    "    p_keep=prob_keep_pos if pos_or_neg else prob_keep_neg\n",
    "    label=1.0 if pos_or_neg else 0.0\n",
    "    cases = list(glob.glob(f'{patient_path}/*.npz'))\n",
    "    if cases:\n",
    "        case_path=random.choice(cases)\n",
    "        #for case_path in glob.iglob(f'{patient_path}/*.npz'):\n",
    "        cnt+=1\n",
    "        print(cnt)\n",
    "        if(pos_or_neg):\n",
    "            print(\"Positive found\")\n",
    "        if np.random.choice([True, False],p=[p_keep,1-p_keep]):\n",
    "            print(f\"Case number {cnt} with name {case_path} is included\")\n",
    "            npz=np.load(case_path)\n",
    "            ct=npz[npz.files[0]]\n",
    "            cts.append(ct)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_HU=4095.0\n",
    "min_HU=0.0\n",
    "downsample_size=384\n",
    "cropped_size=384\n",
    "middle_slice_num=300\n",
    "used_slices=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slices=[Image.fromarray((s.pixel_array/max_HU)*255.0).convert(\"L\").resize((downsample_size,downsample_size),resample=Image.LANCZOS) for s in slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(im, new_width=None, new_height=None):        \n",
    "    width, height = im.size   # Get dimensions\n",
    "    #print(im.size)\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    return im.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cts, labels, test_size=0.3, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTLungSlice(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data, transform=None):\n",
    "        self.X_data = []\n",
    "        self.y_data = []\n",
    "        self.len=0\n",
    "        for ct,lab in zip(X_data,y_data):\n",
    "            slice_num=ct.shape[2]\n",
    "            if slice_num>used_slices:\n",
    "                mid=slice_num//2\n",
    "                used_part=np.moveaxis(ct[:,:,(mid-middle_slice_num//2):(mid+middle_slice_num//2)],2,0)\n",
    "                used_part=np.random.choice(used_part,used_slices,replace=False)\n",
    "                self.X_data.append(used_part)\n",
    "                self.y_data+=([lab]*used_slices)\n",
    "                self.len+=used_slices\n",
    "        self.X_data=np.concatenate(self.X_data).astype(np.uint8)\n",
    "        self.y_data=np.array(self.y_data)\n",
    "        self.transform = transform\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x=self.X_data[index]\n",
    "        y=self.y_data[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(Image.fromarray(x*255/max_HU))\n",
    "        return x, y\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTLungWhole(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data, transform=None):\n",
    "        self.y_data = []\n",
    "        self.X_data = []\n",
    "        self.len=0\n",
    "        for ct,lab in zip(X_data,y_data):\n",
    "            slice_num=ct.shape[2]\n",
    "            if slice_num>used_slices:\n",
    "                mid=slice_num//2\n",
    "                used_part=np.moveaxis(ct[:,:,(mid-middle_slice_num//2):(mid+middle_slice_num//2)],2,0)\n",
    "                used_part=np.random.choice(used_part,used_slices,replace=False)\n",
    "                self.X_data.append(used_part)\n",
    "                self.y_data.append(lab)\n",
    "                self.len+=1\n",
    "        self.X_data=np.asarray(self.X_data).astype(np.uint8)\n",
    "        self.y_data = np.array(y_data)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        y=self.y_data[index]\n",
    "        x=[self.transform(Image.fromarray(item*255/max_HU)) for item in self.X_data[index]] if self.transform else self.X_data[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return len(self.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(cropped_size),\n",
    "    #transforms.ColorJitter(\n",
    "    #    brightness=[0,2],\n",
    "    #    contrast=[0,2]),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(0,1)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(cropped_size),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(0,1)\n",
    "])\n",
    "    \n",
    "train_dataset = CTLungSlice(X_train, torch.FloatTensor(y_train), transform=train_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "test_dataset = CTLungSlice(X_test,torch.FloatTensor(y_test), transform=test_transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "whole_test_dataset = CTLungWhole(X_test,torch.FloatTensor(y_test), transform=test_transform)\n",
    "whole_test_loader = DataLoader(dataset=whole_test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img,_=next(iter(train_loader))\n",
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN, train, validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.elu = nn.ELU()\n",
    "        size_before_fc=((cropped_size-4)//2-4)//2\n",
    "        self.fc1 = nn.Linear(size_before_fc*size_before_fc*64, num_classes)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.max_pool(self.conv1(x)))\n",
    "        x = self.elu(self.max_pool(self.conv2_drop(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred, lab):\n",
    "    binary_pred = pred>0\n",
    "    binary_lab = lab>0.5\n",
    "    common = binary_pred==binary_lab\n",
    "    return torch.sum(common).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_freq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_train_step(model,device,optimizer,criterion,train_loader):\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = images.view(-1, 1, cropped_size, cropped_size)\n",
    "        labels = labels.view(-1, 1)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_freq == 0:\n",
    "            batch_performance=evaluate(outputs, labels)\n",
    "            print(f\"Batch {batch_idx+1} / {len(train_loader)} | Loss = {loss},  Correct = {batch_performance} / {len(labels)}, Ill = {(labels==1).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_eval(model,device,test_loader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    zz = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = images.view(-1, 1, cropped_size, cropped_size)\n",
    "            labels = labels.view(-1, 1)\n",
    "            outputs = model(images)\n",
    "            total += labels.size(0)\n",
    "            correct += evaluate(outputs, labels)\n",
    "            if batch_idx % log_freq == 0:\n",
    "                batch_performance=evaluate(outputs, labels)\n",
    "                print(f\"Batch {batch_idx+1} / {len(test_loader)} |  Correct = {batch_performance} / {len(labels)}, Ill = {(labels==1).sum().item()}\")\n",
    "    return correct,total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del model_base\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "act_max=0.0\n",
    "\n",
    "\n",
    "model_base = CNN(num_classes=1).to(device)\n",
    "criterion_base = nn.BCEWithLogitsLoss() \n",
    "optimizer_base = optim.SGD(model_base.parameters(), lr=learning_rate)\n",
    "\n",
    "params=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    base_train_step(model_base,device,optimizer_base,criterion_base,train_loader)\n",
    "    correct, total = base_model_eval(model_base,device,test_loader)\n",
    "    #correct_tr, total_tr = base_model_eval(model_base,device,train_loader)\n",
    "    print(epoch,\"acc:\",correct/total,\" raw: \",correct,total,)#\"acc_tr:\",correct_tr/total_tr,\" raw_tr: \",correct_tr,total_tr)\n",
    "    if correct/total>act_max:\n",
    "        print(\"IMPROVED\")\n",
    "        act_max = correct/total\n",
    "    params.append(model_base.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_base.state_dict(), \"./Lung_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CNN(num_classes=1)\n",
    "loaded_model.load_state_dict(torch.load(\"./PytorchModels/Lung_model_1\"))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model.to(device)(transforms.ToTensor()(X_train[2][10]).view(1,1,256,256).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_eval_pred(model,device,test_loader):\n",
    "    pred = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            images = images.view(-1, 1, cropped_size, cropped_size)\n",
    "            outputs = model(images).cpu().numpy()\n",
    "            pred.append(outputs[0][0])\n",
    "    return np.asarray(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = base_model_eval_pred(model_base,device,test_loader)\n",
    "target_bool = [y for _,y in test_loader]\n",
    "print(pred)\n",
    "auc = roc_auc_score(target_bool, pred)\n",
    "print('AUC=%.3f' % (auc))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(target_bool, pred)\n",
    "\n",
    "pyplot.plot(fpr, tpr, marker='.', label='LungMetastasis')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(images):\n",
    "    model_base.eval()\n",
    "    batch=[]\n",
    "    for i in range(images.shape[0]):\n",
    "        batch.append(transforms.ToTensor()(images[i,:,:,0]))\n",
    "    batch=torch.stack(batch)\n",
    "    #model_base.to(device)\n",
    "    loaded_model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    #logits = model_base(batch)\n",
    "    logits=loaded_model(batch)\n",
    "    #print(logits>0)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    #print(probs)\n",
    "    return logits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=transforms.CenterCrop(cropped_size)(Image.fromarray(cts[1][:,:,310]*255/max_HU).convert(\"L\"))\n",
    "shape=list(img.size)+[3]\n",
    "shape=tuple(shape)\n",
    "imgg=np.zeros(shape)\n",
    "for i in range(3):\n",
    "    imgg[...,i]=img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(img), \n",
    "                                         batch_predict, # classification function\n",
    "                                         top_labels=1, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=1000) # number of images that will be sent to classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sample_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=200, hide_rest=False)\n",
    "img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=2, hide_rest=False)\n",
    "img_boundry2 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on CTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itt összesítem CT-kre a validáción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_eval_whole(model, device, test_loader):\n",
    "    preds = []\n",
    "    correct = []\n",
    "    with torch.no_grad():\n",
    "        for images, label in test_loader:\n",
    "            slice_preds=[]\n",
    "            for image in images:\n",
    "                image = image.to(device)\n",
    "                image = image.view(-1, 1, cropped_size, cropped_size)\n",
    "                outputs = model(image).cpu().numpy()\n",
    "                slice_preds.append(outputs[0][0])\n",
    "            correct.append(label)\n",
    "            preds.append(np.asarray(slice_preds))\n",
    "    return preds, np.asarray(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds, target_bool = base_model_eval_whole(model_base, device, whole_test_loader)\n",
    "\n",
    "max_preds= [np.max(slices) for slices in preds]\n",
    "mean_preds= [np.mean(slices) for slices in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_max = roc_auc_score(target_bool, max_preds)\n",
    "print('AUC of Max method=%.3f' % (auc_max))\n",
    "\n",
    "print(target_bool, max_preds)\n",
    "fpr, tpr, _ = roc_curve(target_bool, max_preds)\n",
    "\n",
    "pyplot.plot(fpr, tpr, marker='.', label='LungMetastasis')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title('ROC of Max method')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_mean = roc_auc_score(target_bool, mean_preds)\n",
    "print('AUC of Mean method=%.3f' % (auc_mean))\n",
    "\n",
    "print(target_bool, mean_preds)\n",
    "fpr, tpr, _ = roc_curve(target_bool, mean_preds)\n",
    "\n",
    "pyplot.plot(fpr, tpr, marker='.', label='LungMetastasis')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.title('ROC of Mean method')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
